
# ğŸ“˜ GUIDE DU PROJET â€” FilBleu Predictor  
*(Document interne â€” explication simple du travail rÃ©alisÃ©)*

---

## ğŸ¯ Objectif du projet

CrÃ©er une application qui permet :

- dâ€™**analyser les retards** sur le rÃ©seau Fil Bleu (Tours)
- de **prÃ©dire un retard (en minutes)** selon :
  - une ligne
  - un arrÃªt
  - une heure
  - un jour

Le projet suit un **pipeline data complet** :

```

Collecte temps rÃ©el
â†’ Reconstruction des retards
â†’ PrÃ©paration des donnÃ©es
â†’ Machine Learning
â†’ Application Streamlit

```

---

## ğŸ§± Vue dâ€™ensemble du projet (ce quâ€™il fait vraiment)

- Les donnÃ©es **GTFS statiques** donnent les horaires thÃ©oriques
- Les donnÃ©es **GTFS-RT** donnent les horaires rÃ©els observÃ©s
- Lâ€™API **ne fournit pas les retards calculÃ©s**
ğŸ‘‰ on les **reconstruit nous-mÃªmes**
- Ces retards servent ensuite :
  - Ã  lâ€™analyse (Data Viz)
  - Ã  lâ€™entraÃ®nement dâ€™un modÃ¨le ML
  - Ã  une application Streamlit interactive

---

## ğŸ“ Structure du projet (simplifiÃ©e)

```

PROJET-ML-WEB-SCRAPING/
â”‚
â”œâ”€â”€ app/                  # Application Streamlit
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraping/         # Collecte + traitement des donnÃ©es
â”‚   â””â”€â”€ ml/               # PrÃ©paration dataset & entraÃ®nement ML
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md             # Documentation officielle (GitHub)
â”œâ”€â”€ EXPLICATION.md        # Ce fichier (guide interne)
â””â”€â”€ .gitignore

```

âš ï¸ Les dossiers `data/` et `models/` existent **en local**,  
mais **ne sont pas sur GitHub** (trop volumineux).

---

## ğŸ“Š Les donnÃ©es utilisÃ©es

### 1ï¸âƒ£ GTFS statique (horaires thÃ©oriques)

ğŸ“ **RÃ´le** : savoir **quand un bus est censÃ© passer**

- ArrÃªts (2 146)
- Lignes (44)
- Horaires programmÃ©s (~1,4 million)

Ces donnÃ©es servent de **rÃ©fÃ©rence thÃ©orique**.

---

### 2ï¸âƒ£ GTFS-RT (temps rÃ©el)

ğŸ“ **RÃ´le** : savoir **quand le bus passe rÃ©ellement**

- DonnÃ©es collectÃ©es via lâ€™API Fil Bleu
- Format binaire `.bin` (Protocol Buffers)
- Chaque fichier = un **snapshot** du rÃ©seau Ã  un instant donnÃ©

ğŸ‘‰ Ces donnÃ©es sont **brutes** et **illisibles directement**.

---

## ğŸ”§ Scripts principaux (expliquÃ©s simplement)

### `scrape_gtfs_rt.py` â€” Collecte temps rÃ©el

- Se connecte Ã  lâ€™API Fil Bleu
- TÃ©lÃ©charge les horaires rÃ©els
- Sauvegarde des fichiers `.bin`

ğŸ‘‰ Sert uniquement Ã  **collecter la matiÃ¨re premiÃ¨re**

---

### `parse_gtfs_rt.py` â€” Conversion `.bin â†’ CSV`

Pourquoi ?
- Les fichiers `.bin` ne sont pas exploitables
- On les transforme en CSV lisible

RÃ©sultat :
- Un fichier avec :
  - trip_id
  - stop_id
  - heure rÃ©elle (timestamp)

---

### `calculate_delays.py` â€” â­ CÅ’UR DU PROJET !!!!

ğŸ“Œ **ProblÃ¨me de dÃ©part**  
Lâ€™API Fil Bleu fournit un champ `delay`, mais il vaut **toujours 0**.

ğŸ“Œ **Solution mise en place**
On calcule nous-mÃªmes :

```

retard (minutes) = heure rÃ©elle - heure thÃ©orique

````

Ce que fait le script :
1. Charge les horaires thÃ©oriques (GTFS statique)
2. Charge les horaires rÃ©els (GTFS-RT parsÃ©)
3. Fusionne sur `trip_id` + `stop_id`
4. Calcule le retard !!!
5. Corrige le fuseau horaire (UTC â†’ Europe/Paris)

ğŸ“Š RÃ©sultat :
- Un dataset final `delays_calculated.csv`
- Retards positifs = retard
- Retards nÃ©gatifs = avance

---

## ğŸ¤– Machine Learning (ce qui a Ã©tÃ© fait)

### Pourquoi un problÃ¨me de rÃ©gression ?

Lâ€™objectif du projet est de **prÃ©dire un retard en minutes**.

Un retard :
- nâ€™est pas une catÃ©gorie (petit / moyen / grand),
- mais une **valeur numÃ©rique continue**  
  (exemples : 1.5 min, 4.2 min, 12 min, -2 min).

â¡ï¸ Ce type de problÃ¨me correspond Ã  une **rÃ©gression**  
(prÃ©dire un nombre rÃ©el), et non Ã  une classification.

---

### Variable cible

La variable Ã  prÃ©dire est : delay_minutes
Elle reprÃ©sente :
- un **retard positif** â†’ le vÃ©hicule arrive en retard,
- un **retard nÃ©gatif** â†’ le vÃ©hicule arrive en avance.

Cette variable est directement exploitable dâ€™un point de vue mÃ©tier
(car exprimÃ©e en minutes).

---

### Features utilisÃ©es (variables explicatives)

Le retard dÃ©pend fortement du **contexte de circulation**.
Les principales variables utilisÃ©es sont :

- **heure** : le trafic varie fortement selon le moment de la journÃ©e
- **jour de la semaine** : semaine â‰  week-end
- **heure de pointe** : congestion plus forte
- **week-end** : comportement diffÃ©rent du rÃ©seau
- **ligne** : certaines lignes sont structurellement plus sensibles aux retards
- **arrÃªt** : localisation et frÃ©quence influencent le retard

Ces variables permettent de dÃ©crire une situation rÃ©elle de passage dâ€™un bus.

---

### ModÃ¨les testÃ©s

Plusieurs modÃ¨les ont Ã©tÃ© Ã©valuÃ©s :

- **Baseline**  
  â†’ prÃ©diction simple servant de point de comparaison

- **Random Forest / Gradient Boosting**  
  â†’ modÃ¨les non linÃ©aires capables de capturer :
  - effets dâ€™heures de pointe
  - diffÃ©rences entre lignes
  - interactions entre variables

Ces modÃ¨les sont bien adaptÃ©s aux donnÃ©es tabulaires
et aux phÃ©nomÃ¨nes non linÃ©aires.

---

### MÃ©trique choisie : MAE

La mÃ©trique principale est la **MAE (Mean Absolute Error)**.

Pourquoi ?
- Elle sâ€™exprime en **minutes**
- Elle est **facile Ã  interprÃ©ter**
- Une MAE de 3 signifie :
  > â€œEn moyenne, la prÃ©diction se trompe de 3 minutesâ€

Câ€™est une mÃ©trique directement comprÃ©hensible pour un usage mÃ©tier.

---

Le modÃ¨le retenu est le **Gradient Boosting**.

MÃªme si les Random Forest sont souvent efficaces sur des donnÃ©es tabulaires,
le Gradient Boosting obtient ici de **meilleures performances sur le jeu de test** :

- MAE plus faible
- RMSE plus faible
- RÂ² plus Ã©levÃ©

Cela indique une meilleure capacitÃ© Ã  prÃ©dire prÃ©cisÃ©ment
le retard en minutes.

Le choix du modÃ¨le est donc basÃ© sur les **rÃ©sultats observÃ©s**
et non sur un choix thÃ©orique.

CONCLUSION : On a testÃ© plusieurs modÃ¨les.
Le Gradient Boosting a Ã©tÃ© retenu car il obtient la plus faible erreur moyenne en minutes sur le jeu de test.
Le choix du modÃ¨le est donc basÃ© sur les rÃ©sultats observÃ©s, et non sur un choix thÃ©orique.

---

## ğŸ“Š Application Streamlit

Lâ€™application permet :

- une page **Data Visualization**
  - tendances horaires
  - lignes les plus en retard
  - arrÃªts les plus impactÃ©s
- une page **PrÃ©diction**
  - choix ligne / arrÃªt / heure / jour
  - estimation du retard
  - indicateur de risque ğŸŸ¢ğŸŸ¡ğŸ”´

ğŸ‘‰ Câ€™est la **mise en valeur finale** du travail data + ML.

---

## ğŸ“¦ DonnÃ©es & GitHub (point important)

Les dossiers suivants **ne sont pas sur GitHub** :
- `data/`
- `models/`

Pourquoi ?
- Trop volumineux
- Mauvaise pratique professionnelle

ğŸ‘‰ Les donnÃ©es sont **reconstruites via les scripts** :
```powershell
python src/scraping/scrape_gtfs_rt.py
python src/ml/prepare_dataset.py
python src/ml/train_model.py
````

---

## âœ… Ce qui a Ã©tÃ© fait (rÃ©sumÃ© clair)

âœ”ï¸ Collecte GTFS-RT
âœ”ï¸ Parsing Protocol Buffers
âœ”ï¸ Reconstruction des retards
âœ”ï¸ Dataset exploitable
âœ”ï¸ ModÃ©lisation ML
âœ”ï¸ Application Streamlit
âœ”ï¸ Repo GitHub propre (code only)

ğŸ‘‰ Le projet couvre **toute la chaÃ®ne data**.

---

## ğŸ§  Ce que le projet dÃ©montre

* ComprÃ©hension des donnÃ©es temps rÃ©el
* Manipulation de formats complexes
* Raisonnement data (pas juste appliquer un modÃ¨le)
* Logique mÃ©tier (retard en minutes)
* CapacitÃ© Ã  livrer une application fonctionnelle

---

## ğŸ“Œ Point clÃ© Ã  retenir

> Le cÅ“ur du projet nâ€™est PAS le modÃ¨le ML
> ğŸ‘‰ câ€™est la **reconstruction fiable du retard**

Sans cette Ã©tape :

* pas dâ€™analyse
* pas de prÃ©diction
* pas de valeur mÃ©tier

---




