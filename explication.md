# ğŸ“˜ GUIDE DU PROJET - PrÃ©diction des Retards Fil Bleu


## ğŸ¯ Objectif du Projet

CrÃ©er une application qui prÃ©dit les retards des bus/trams de Fil Bleu (Tours) en utilisant le Machine Learning.

**Pipeline complet :**
```
Collecte donnÃ©es â†’ Calcul des retards â†’ PrÃ©paration â†’ ML â†’ Application Streamlit
```

---

## ğŸ“ Structure du Projet
```
Machine Learning/
â”‚
â”œâ”€â”€ README.md                    # Documentation officielle (pour le rapport)
â”œâ”€â”€ EXPLICATION.md               # Ce fichier (guide pour nous)
â”œâ”€â”€ requirements.txt             # BibliothÃ¨ques Python nÃ©cessaires
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # âš ï¸ NE JAMAIS MODIFIER CES FICHIERS !
â”‚   â”‚   â”œâ”€â”€ gtfs/                # Horaires thÃ©oriques du rÃ©seau
â”‚   â”‚   â”‚   â”œâ”€â”€ stops.txt        # 2 146 arrÃªts
â”‚   â”‚   â”‚   â”œâ”€â”€ routes.txt       # 44 lignes
â”‚   â”‚   â”‚   â”œâ”€â”€ stop_times.txt   # 1 469 821 horaires programmÃ©s
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ gtfs_rt/             # DonnÃ©es temps rÃ©el collectÃ©es
â”‚   â”‚       â”œâ”€â”€ trip_updates_20251212_223805.bin  (160 fichiers)
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/               # DonnÃ©es transformÃ©es
â”‚   â”‚   â”œâ”€â”€ gtfs_rt_parsed.csv         # DonnÃ©es .bin converties en CSV
â”‚   â”‚   â””â”€â”€ delays_calculated.csv      # ğŸ¯ Dataset final avec retards calculÃ©s
â”‚   â”‚
â”‚   â””â”€â”€ final/                   # Dataset ML prÃªt (Ã  crÃ©er)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraping/                # Scripts de collecte
â”‚   â”‚   â”œâ”€â”€ download_gtfs.py           # TÃ©lÃ©charge GTFS statique
â”‚   â”‚   â”œâ”€â”€ explore_gtfs.py            # Explore les donnÃ©es GTFS
â”‚   â”‚   â”œâ”€â”€ scrape_gtfs_rt.py          # Collecte API temps rÃ©el
â”‚   â”‚   â”œâ”€â”€ parse_gtfs_rt.py           # Convertit .bin â†’ CSV
â”‚   â”‚   â””â”€â”€ calculate_delays.py        # ğŸ”¥ CALCULE LES RETARDS RÃ‰ELS
â”‚   â”‚
â”‚   â””â”€â”€ ml/                      # Scripts ML (Ã  crÃ©er)
â”‚
â””â”€â”€ app/                         # Application Streamlit (Ã  crÃ©er)
```

---

## ğŸ“Š Les DonnÃ©es CollectÃ©es

### GTFS Statique (horaires thÃ©oriques)

**OÃ¹ :** `data/raw/gtfs/`  
**Format :** Fichiers .txt (CSV)  
**Ce que c'est :** Les horaires "normaux" affichÃ©s aux arrÃªts

**Fichiers importants :**
- `stops.txt` : Liste des 2 146 arrÃªts avec coordonnÃ©es GPS
- `routes.txt` : Liste des 44 lignes (Tram A, Bus 1-70, etc.)
- `stop_times.txt` : 1 469 821 horaires programmÃ©s (qui passe oÃ¹ et quand)
- `trips.txt` : Informations sur les trajets

---

### GTFS-RT (temps rÃ©el)

**OÃ¹ :** `data/raw/gtfs_rt/`  
**Format :** Fichiers .bin (Protocol Buffers - format binaire)  
**Ce que c'est :** L'heure RÃ‰ELLE de passage des bus (collectÃ©e en direct)

**Collecte effectuÃ©e :**
- **Samedi 13/12** : 155 fichiers (12h40 â†’ 21h00)
- **Lundi 15/12** : 3 fichiers (18h33)
- **Vendredi 12/12** : 2 fichiers (22h38, 23h02)
- **Total : 160 fichiers = 291 699 passages**

**Nom des fichiers :**
```
trip_updates_20251213_150053.bin
             ^^^^^^^^  ^^^^^^
             Date      Heure (15h00:53)
```

---

## ğŸ”§ Les Scripts et leur RÃ´le

### 1. `explore_gtfs.py` - Explorer le rÃ©seau

**Ce qu'il fait :**
- Charge les fichiers GTFS statiques
- Affiche combien de lignes, arrÃªts, trajets
- Liste toutes les lignes du rÃ©seau

**Comment l'utiliser :**
```powershell
python src\scraping\explore_gtfs.py
```

**RÃ©sultat :**
```
ğŸš Nombre d'arrÃªts : 2146
ğŸšŒ Nombre de lignes : 44
ğŸ“ Liste des lignes : Tram A, Bus 1, Bus 2...
```

---

### 2. `scrape_gtfs_rt.py` - Collecter les donnÃ©es temps rÃ©el

**Ce qu'il fait :**
- Se connecte Ã  l'API Fil Bleu
- RÃ©cupÃ¨re les horaires temps rÃ©el
- Sauvegarde dans `data/raw/gtfs_rt/`

**Test simple (1 collecte) :**
```powershell
python src\scraping\scrape_gtfs_rt.py
```

**Collecte continue (dÃ©jÃ  faite) :**
- Samedi : collecte automatique pendant 8h
- Lundi : 3 collectes manuelles

---

### 3. `parse_gtfs_rt.py` - Convertir .bin en CSV

**Pourquoi ce script ?**

Les fichiers `.bin` sont **illisibles** :
```
ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½trip_idï¿½ï¿½stop_idï¿½ï¿½...  âŒ
```

Le parser les convertit en **CSV exploitable** :
```csv
trip_id,stop_id,arrival_time_unix,...  âœ…
```

**Comment l'utiliser :**
```powershell
python src\scraping\parse_gtfs_rt.py
```

**RÃ©sultat :**
- CrÃ©e `data/processed/gtfs_rt_parsed.csv`
- 291 699 passages lisibles en CSV

---

### 4. `calculate_delays.py` - ğŸ”¥ CALCULER LES RETARDS

**âš ï¸ SCRIPT CRUCIAL !**

**Pourquoi il existe :**

L'API Fil Bleu envoie :
- âœ… Heure thÃ©orique (prÃ©vue) : `22:30:00`
- âœ… Heure rÃ©elle (actuelle) : `22:35:00`
- âŒ Mais PAS le retard calculÃ© (toujours Ã  `0`)

**â†’ On doit calculer nous-mÃªmes : Retard = Heure rÃ©elle - Heure thÃ©orique**

**Ce que fait le script :**
1. Charge GTFS statique (horaires thÃ©oriques)
2. Charge GTFS-RT parsÃ© (horaires rÃ©els)
3. Fusionne les deux sur `trip_id` + `stop_id`
4. Calcule : `retard = heure_rÃ©elle - heure_thÃ©orique`
5. Corrige le fuseau horaire (UTC â†’ Europe/Paris)

**Comment l'utiliser :**
```powershell
python src\scraping\calculate_delays.py
```

**RÃ©sultat :**
```
ğŸ“Š STATISTIQUES DES RETARDS :
  Retard moyen : 4.93 minutes
  Retard mÃ©dian : 1.92 minutes
  Retard max : 150.92 minutes
  Retard min : -19.08 minutes (en avance)
  
ğŸ’¾ DonnÃ©es sauvegardÃ©es : data/processed/delays_calculated.csv
```

---

## âœ… Ce Qui a Ã‰tÃ© Fait (Ã‰tat Actuel)

**Phase 1 : Collecte et traitement des donnÃ©es âœ… TERMINÃ‰E**

- [x] Structure du projet crÃ©Ã©e
- [x] BibliothÃ¨ques Python installÃ©es (`pip install -r requirements.txt`)
- [x] DonnÃ©es GTFS statiques tÃ©lÃ©chargÃ©es (1.4M d'horaires)
- [x] Script d'exploration crÃ©Ã© et testÃ©
- [x] 160 fichiers temps rÃ©el collectÃ©s (291 699 passages)
- [x] Parser crÃ©Ã© : .bin â†’ CSV
- [x] **Retards calculÃ©s** : fusion GTFS + GTFS-RT
- [x] **Dataset final prÃªt** : `delays_calculated.csv`

**â†’ Progression : 40% du projet**

---

## ğŸš€ Prochaines Ã‰tapes

### Phase 2 : PrÃ©paration des donnÃ©es ML (Ã€ FAIRE)

**Objectif :** Transformer `delays_calculated.csv` en dataset exploitable pour le ML

**TÃ¢ches :**
1. **Feature engineering** :
   - Extraire l'heure (8h, 18h...)
   - Extraire le jour de la semaine (lundi, samedi...)
   - CrÃ©er variable "est_heure_pointe" (7h-9h, 17h-19h)
   - Encoder les variables catÃ©gorielles (ligne, arrÃªt)

2. **Nettoyage** :
   - Supprimer les retards aberrants (> 60 min = incidents)
   - GÃ©rer les valeurs manquantes

3. **Split train/test** :
   - 80% entraÃ®nement
   - 20% test

---

### Phase 3 : Machine Learning (Ã€ FAIRE)

**ModÃ¨les Ã  tester :**
1. RÃ©gression linÃ©aire (baseline)
2. Random Forest
3. XGBoost

**MÃ©triques :**
- MAE (erreur moyenne en minutes)
- RMSE
- RÂ²

---

### Phase 4 : Application Streamlit (Ã€ FAIRE)

**Interface utilisateur :**
- SÃ©lectionner ligne, arrÃªt, heure
- Afficher prÃ©diction du retard
- Indicateur de risque (fluide / modÃ©rÃ© / Ã©levÃ©)

---

## ğŸ’¡ Commandes Utiles

**Voir la structure des dossiers :**
```powershell
tree /F
```

**Installer les bibliothÃ¨ques (si pas fait) :**
```powershell
pip install -r requirements.txt
```

**Lancer un script :**
```powershell
python src\scraping\nom_du_script.py
```

**Voir les donnÃ©es collectÃ©es :**
```powershell
import pandas as pd
df = pd.read_csv('data/processed/delays_calculated.csv')
print(df.head())
```

---

## ğŸ“ Points Importants pour le Rapport

### Justification de l'approche

**ProblÃ¨me rencontrÃ© :**
L'API GTFS-RT de Fil Bleu ne fournit pas les retards calculÃ©s (champ `delay` toujours Ã  `0`).

**Solution implÃ©mentÃ©e :**
Calcul manuel des retards en fusionnant :
- Horaires thÃ©oriques (GTFS statique `stop_times.txt`)
- Horaires rÃ©els (GTFS-RT `arrival_time_unix`)
- Gestion du fuseau horaire Europe/Paris (+1h par rapport Ã  UTC)

**RÃ©sultat :**
- 291 699 passages avec retards calculÃ©s
- Retard moyen : 4.93 minutes
- Distribution rÃ©aliste (mÃ©diane 1.92 min, max 150 min)

**CompÃ©tences dÃ©montrÃ©es :**
- Web scraping API temps rÃ©el
- Parsing de formats complexes (Protocol Buffers)
- Fusion de datasets hÃ©tÃ©rogÃ¨nes
- Calculs temporels avec fuseaux horaires

---

## âš ï¸ Points d'Attention

1. **Ne JAMAIS modifier `data/raw/`** : Ce sont les donnÃ©es originales
2. **Les timestamps sont en UTC** : Toujours convertir en Europe/Paris
3. **Le champ `delay` de l'API est inutile** : Toujours Ã  0, on calcule nous-mÃªmes
4. **Les retards > 60 min sont souvent des incidents** : Ã€ filtrer pour le ML

---

## ğŸ“Š Statistiques Finales

**DonnÃ©es collectÃ©es :**
- 160 snapshots temporels
- 291 699 passages enregistrÃ©s
- Sur 2 jours (samedi + lundi)

**Retards calculÃ©s :**
- Retard moyen : 4.93 min
- Retard mÃ©dian : 1.92 min
- 95% des retards entre -2 et +15 min

---

**Ã‰tat actuel : 40% du projet terminÃ©**  
**Prochaine Ã©tape : Feature engineering + ML**  
**Deadline : DÃ©but janvier 2025**