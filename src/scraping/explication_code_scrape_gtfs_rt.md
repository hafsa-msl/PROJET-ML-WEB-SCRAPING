# 1Ô∏è‚É£ Les "Outils" (Imports)

üìç R√¥le : Pr√©parer les accessoires n√©cessaires au script.
- requests : biblioth√®que standard en Python pour communiquer avec le monde ext√©rieur via internet. Il va chercher les donn√©es sur le web.
- pandas : Importer et transformer les donn√©es
- datetime / time : La montre et le chrono. Pour savoir l'heure et g√©rer les pauses.

- pathlib : Pour cr√©er les dossiers et ranger les fichiers au bon endroit.

# üìç Scrapping donn√©es de trajets = trip_updates 
## Cr√©ation d'une fonction pour aller chercher les donn√©es

- def scrape_trip_updates()= fonction principale qui va chercher les donn√©es de trajets en temps r√©el= arrets et horaires de passage 
ex: le bus 20 est pass√© √† l'arr√™t X √† 14h30

- url= "https://data.filbleu.fr/ws-tr/gtfs-rt/opendata/trip-updates" = adresse web o√π se trouvent les donn√©es de trajets en temps r√©el.

- try: =permet au code de tester quelque chose
    print(f"Requ√™te vers l'API GTFS-RT Updates")
    response = requests.get(url, timeout=10)= permet au code de tester quelque chose
    response.raise_for_status()= Cette ligne v√©rifie si le serveur de Tours a bien donn√© l'acc√®s. Si le serveur r√©pond "Erreur" ou "Acc√®s refus√©", cette ligne le d√©tecte imm√©diatement pour √©viter de travailler avec un fichier vide.

## Etape de v√©rification de la r√©ponse du serveur

- print(f" R√©ponse re√ßue : {response.status_code}")= Si √ßa affiche 200, c'est "Vert" : la connexion a r√©ussi. Si √ßa affiche 429 (ton erreur de tout √† l'heure), c'est "Rouge" : le serveur te demande d'arr√™ter car tu as fait trop de requ√™tes.

- print(f"Taille : {len(response.content)} bytes")= la taille du fichier re√ßu. √áa permet de v√©rifier si le fichier contient vraiment des donn√©es. Si la taille est de 0 bytes, c'est que le fichier est vide (il y a eu un probl√®me). Si elle est de plusieurs milliers de bytes, c'est qu'on a bien r√©cup√©r√© les donn√©es des bus.

- print(f"Content-Type : {response.headers.get('Content-Type')}")= √áa confirme la nature du fichier. Pour Fil Bleu, il doit t'afficher quelque chose qui contient x-protobuf

Ces trois lignes sont tes outils de contr√¥le. Elles ne servent pas √† collecter la donn√©e, mais √† v√©rifier la qualit√© de ce qui vient d'arriver sur ton ordinateur

## Etape du stockage des donn√©es

- timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")= demande √† l'ordinateur l'heure exacte √† la seconde pr√®s. Le format bizarre (%Y%m%d...) permet d'√©crire la date comme ceci : 20251226_125030 (26 d√©cembre 2025 √† 12h 50min 30s)

- output_dir = Path("data/raw/gtfs_rt")= chemin o√π le fichier sera stock√©. Ici, on cr√©e un dossier "data", puis un sous-dossier "raw", puis un sous-sous-dossier "gtfs_rt"

- output_dir.mkdir(parents=True, exist_ok=True)= v√©rifie si le dossier existe d√©j√†. Si ce n'est pas le cas, il le cr√©e. parents=True permet de cr√©er aussi les dossiers parents s'ils n'existent pas (data et raw). exist_ok=True √©vite de g√©n√©rer une erreur si le dossier existe d√©j√†.
        
- output_file = output_dir / f"trip_updates_{timestamp}.bin" = nom du fichier. Il sera nomm√© "trip_updates_20251226_125030.bin" par exemple.
        
- with open(output_file, 'wb') as f:= ouvre le fichier en mode √©criture binaire (wb = write binary). Le mode binaire est n√©cessaire car les donn√©es sont au format protobuf, qui n'est pas du texte classique.
    f.write(response.content)= √©crit les donn√©es re√ßues dans le fichier. 
        
- print(f"Donn√©es sauvegard√©es : {output_file}")= affiche un message de confirmation avec le chemin complet du fichier sauvegard√©.
        
- return True= indique que la fonction s'est bien d√©roul√©e jusqu'au bout.

- except requests.exceptions.RequestException as e:= capture les erreurs li√©es √† la requ√™te HTTP (probl√®me de connexion, timeout, etc.)

- print(f"Erreur lors de la requ√™te : {e}")= affiche un message d'erreur d√©taill√©.
    return False= indique que la fonction a rencontr√© un probl√®me.

-except Exception as e:= capture toute autre erreur inattendue.
    print(f"Erreur inattendue : {e}")
    return False

## Conclusion code
- La fonction scrape_trip_updates() est con√ßue pour aller chercher les donn√©es de trajets en temps r√©el depuis l'API GTFS-RT de Fil Bleu, v√©rifier la qualit√© de la r√©ponse, et sauvegarder les donn√©es dans un fichier local avec un nom horodat√©. Elle g√®re √©galement les erreurs potentielles lors de la requ√™te HTTP.

# üìçScraping donn√©es de positions = vehicle_positions
## Cr√©ation d'une fonction pour aller chercher les donn√©es

- def scrape_vehicle_positions()= fonction principale qui va chercher les donn√©es de positions en temps r√©el= position g√©ographique des bus 
ex: le bus 20 est √† tel endroit √† 14h30

- url= "https://data.filbleu.fr/ws-tr/gtfs-rt/opendata/vehicle-positions" = adresse web o√π se trouvent les donn√©es de positions en temps r√©el.

- try: =permet au code de tester quelque chose
    print(f"Requ√™te vers l'API GTFS-RT Vehicle Positions")
    response = requests.get(url, timeout=10)= permet au code de tester quelque chose
    response.raise_for_status()= Cette ligne v√©rifie si le serveur de Tours a bien donn√© l'acc√®s. Si le serveur r√©pond "Erreur" ou "Acc√®s refus√©", cette ligne le d√©tecte imm√©diatement pour √©viter de travailler avec un fichier vide.

## Etape de v√©rification de la r√©ponse du serveur

- print(f" R√©ponse re√ßue : {response.status_code}")= Si √ßa affiche 200, c'est "Vert" : la connexion a r√©ussi. Si √ßa affiche 429 (ton erreur de tout √† l'heure), c'est "Rouge" : le serveur te demande d'arr√™ter car tu as fait trop de requ√™tes.

- print(f"Taille : {len(response.content)} bytes")= la taille du fichier re√ßu. √áa permet de v√©rifier si le fichier contient vraiment des donn√©es. Si la taille est de 0 bytes, c'est que le fichier est vide (il y a eu un probl√®me). Si elle est de plusieurs milliers de bytes, c'est qu'on a bien r√©cup√©r√© les donn√©es des bus.

- print(f"Content-Type : {response.headers.get('Content-Type')}")= √áa confirme la nature du fichier. Pour Fil Bleu, il doit t'afficher quelque chose qui contient x-protobuf

Ces trois lignes sont tes outils de contr√¥le. Elles ne servent pas √† collecter la donn√©e, mais √† v√©rifier la qualit√© de ce qui vient d'arriver sur ton ordinateur

## Etape du stockage des donn√©es

- timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")= demande √† l'ordinateur l'heure exacte √† la seconde pr√®s. Le format bizarre (%Y%m%d...) permet d'√©crire la date comme ceci : 20251226_125030 (26 d√©cembre 2025 √† 12h 50min 30s)

- output_dir = Path("data/raw/gtfs_rt")= chemin o√π le fichier sera stock√©. Ici, on cr√©e un dossier "data", puis un sous-dossier "raw", puis un sous-sous-dossier "gtfs_rt"

- output_dir.mkdir(parents=True, exist_ok=True)= v√©rifie si le dossier existe d√©j√†. Si ce n'est pas le cas, il le cr√©e. parents=True permet de cr√©er aussi les dossiers parents s'ils n'existent pas (data et raw). exist_ok=True √©vite de g√©n√©rer une erreur si le dossier existe d√©j√†.

- output_file = output_dir / f"vehicle_positions_{timestamp}.bin" = nom du fichier. Il sera nomm√© "vehicle_positions_20251226_125030.bin" par exemple.

- with open(output_file, 'wb') as f:= ouvre le fichier en mode √©criture binaire (wb = write binary). Le mode binaire est n√©cessaire car les donn√©es sont au format protobuf, qui n'est pas du texte classique.
    f.write(response.content)= √©crit les donn√©es re√ßues dans le fichier.
- print(f"Donn√©es sauvegard√©es : {output_file}")= affiche un message de confirmation avec le chemin complet du fichier sauvegard√©.
- return True= indique que la fonction s'est bien d√©roul√©e jusqu'au bout.
- except requests.exceptions.RequestException as e:= capture les erreurs li√©es √† la requ√™te HTTP (probl√®me de connexion, timeout, etc.)
    print(f"Erreur lors de la requ√™te : {e}")= affiche un message d'erreur d√©taill√©.
    return False= indique que la fonction a rencontr√© un probl√®me.
-except Exception as e:= capture toute autre erreur inattendue.
    print(f"Erreur inattendue : {e}")
    return False

## Conclusion code
- La fonction scrape_vehicle_positions() est con√ßue pour aller chercher les donn√©es de positions en temps r√©el depuis l'API GTFS-RT de Fil Bleu, v√©rifier la qualit√© de la r√©ponse, et sauvegarder les donn√©es dans un fichier local avec un nom horodat√©. Elle g√®re √©galement les erreurs potentielles lors de la requ√™te HTTP.



## Cr√©ation d'une fonction pour collecter les donn√©es de mani√®re continue

- def collecte_continue(duree_minutes=5, intervalle_secondes=60):= fonction qui permet de collecter les donn√©es de mani√®re continue pendant une dur√©e d√©finie (duree_minutes) avec un intervalle entre chaque collecte (intervalle_secondes).

- print("="*60)= affiche une ligne de s√©paration pour la lisibilit√© dans la console.

- print(" D√âBUT DE LA COLLECTE CONTINUE")= affiche un message indiquant le d√©but de la collecte continue.

- print("="*60)= affiche une ligne de s√©paration pour la lisibilit√© dans la console.

- print(f" Dur√©e : {duree_minutes} minutes")= affiche la dur√©e totale de la collecte continue.

- print(f"Intervalle : {intervalle_secondes} secondes")= affiche l'intervalle entre chaque collecte.

-print(f" D√©but : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")= affiche l'heure de d√©but de la collecte.

- print("="*60)= affiche une ligne de s√©paration pour la lisibilit√© dans la console.
    
- debut = time.time()= enregistre le temps de d√©but de la collecte en secondes depuis l'√©poque (1er janvier 1970).

- fin = debut + (duree_minutes * 60)= calcule le temps de fin de la collecte en ajoutant la dur√©e totale (en secondes) au temps de d√©but.

- collecte_num = 1 = initialise un compteur pour le nombre de collectes effectu√©es.
    
- while time.time() < fin: = boucle qui continue tant que le temps actuel est inf√©rieur au temps de fin.
        
- print(f"\n\n{'='*60}")= affiche une ligne de s√©paration pour la lisibilit√© dans la console.

- print(f" COLLECTE #{collecte_num}")= affiche le num√©ro de la collecte en cours.

- print(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")= affiche l'heure actuelle.

- print('='*60) = affiche une ligne de s√©paration pour la lisibilit√© dans la console.
        

## Collecter les retards

- success1 = scrape_trip_updates()= appelle la fonction scrape_trip_updates() pour collecter les donn√©es de trajets et stocke le r√©sultat (True ou False) dans la variable success1.
        
## Collecter les positions

- success2 = scrape_vehicle_positions()= appelle la fonction scrape_vehicle_positions() pour collecter les donn√©es de positions et stocke le r√©sultat (True ou False) dans la variable success2.

        
- if success1 and success2: = v√©rifie si les deux collectes ont r√©ussi.

- print(f"\n Collecte #{collecte_num} r√©ussie !") = affiche un message indiquant que la collecte a r√©ussi.

- else:

- if not success1 and not success2: = v√©rifie si les deux collectes ont √©chou√©.

- print(f"\n Collecte #{collecte_num} √©chou√©e !") = affiche un message indiquant que la collecte a √©chou√©.
        else:
            print(f"\n Collecte #{collecte_num} partiellement r√©ussie")
        
collecte_num += 1

## Attendre avant la prochaine collecte

- temps_restant = fin - time.time() = calcule le temps restant avant la fin de la collecte continue.

- if temps_restant > intervalle_secondes: = v√©rifie si le temps restant est sup√©rieur √† l'intervalle d√©fini.

- print(f"\n Pause de {intervalle_secondes} secondes...") = affiche un message indiquant la pause avant la prochaine collecte.
        
- time.sleep(intervalle_secondes) = met le script en pause pendant l'intervalle d√©fini.
        else:
            break
    
- print("\n\n" + "="*60)  = affiche une ligne de s√©paration pour la lisibilit√© dans la console.
    
- print(" COLLECTE TERMIN√âE") = affiche un message indiquant la fin de la collecte continue.

- print("="*60) = affiche une ligne de s√©paration pour la lisibilit√© dans la console.

- print(f"Nombre de collectes : {collecte_num - 1}") = affiche le nombre total de collectes effectu√©es.

- print(f" Fin : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}") = affiche l'heure de fin de la collecte.

## Test des fonctions de scrapping

- if __name__ == "__main__": = permet d'ex√©cuter le code suivant uniquement si le script est ex√©cut√© directement (et non import√© comme module).

- print("\n TEST DE CONNEXION √Ä L'API GTFS-RT\n") = affiche un message indiquant le d√©but des tests de connexion √† l'API GTFS-RT.
    
- print("Test 1 : R√©cup√©ration des retards (trip_updates)")
    scrape_trip_updates()
    
- print("\n" + "="*60 + "\n")
    
- print("Test 2 : R√©cup√©ration des positions (vehicle_positions)")
    scrape_vehicle_positions()
    
- print("\n\n" + "="*60)
- print(" Tests termin√©s !")
- print("="*60)
- print("\nPour lancer une collecte continue :")
- print("  D√©commente la ligne 'collecte_continue()' en bas du fichier")
- print("  Ou lance : collecte_continue(duree_minutes=10, intervalle_secondes=60)")
    
- 
collecte_continue(duree_minutes=503, intervalle_secondes=180)
